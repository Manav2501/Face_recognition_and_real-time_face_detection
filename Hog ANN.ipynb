{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras import models,Model\n",
    "from keras.layers import Dense,GaussianNoise, Dropout,Input\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "%matplotlib inline\n",
    "from skimage.feature import hog\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\skimage\\feature\\_hog.py:150: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15. To supress this message specify explicitly the normalization method.\n",
      "  skimage_deprecation)\n",
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\skimage\\feature\\_hog.py:248: skimage_deprecation: Argument `visualise` is deprecated and will be changed to `visualize` in v0.16\n",
      "  'be changed to `visualize` in v0.16', skimage_deprecation)\n"
     ]
    }
   ],
   "source": [
    "def isSubstring(s1, s2): \n",
    "    M = len(s1) \n",
    "    N = len(s2) \n",
    "  \n",
    "    # A loop to slide pat[] one by one  \n",
    "    for i in range(N - M + 1): \n",
    "  \n",
    "        # For current index i, \n",
    "        # check for pattern match  \n",
    "        for j in range(M): \n",
    "            if (s2[i + j] != s1[j]): \n",
    "                break\n",
    "              \n",
    "        if j + 1 == M : \n",
    "            return i \n",
    "  \n",
    "    return -1\n",
    "\n",
    "dataSet = []\n",
    "person = []\n",
    "horiSet = []\n",
    "\n",
    "count = 0\n",
    "folder = \"C:/Users/Dell/Desktop/ML_project/Dataset/train_RGB/\"\n",
    "for filename in os.listdir(folder):\n",
    "    if isSubstring(\".png\",filename)!=-1:\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "#         print(img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        img = cv2.resize(img, (200,200))\n",
    "        fd, img = hog(img,visualise=True)\n",
    "        img = np.ravel(img)\n",
    "        if img is not None:\n",
    "            numbers = re.findall('\\d+',filename)\n",
    "            numbers = list(map(int,numbers))\n",
    "            person.append(numbers[0])\n",
    "            horiSet.append(img.T)\n",
    "            dataSet.append(img)\n",
    "            count = count + 1\n",
    "           \n",
    "        \n",
    "dataSet_test = []\n",
    "person_test = []\n",
    "horiSet_test = []\n",
    "\n",
    "folder = \"C:/Users/Dell/Desktop/ML_project/Dataset/test_RGB/\"\n",
    "for filename in os.listdir(folder):\n",
    "    if isSubstring(\".png\",filename)!=-1:\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        img = cv2.resize(img, (200, 200))\n",
    "        fd, img = hog(img, visualise=True)\n",
    "        img = np.ravel(img)\n",
    "        if img is not None:\n",
    "            numbers = re.findall('\\d+',filename)\n",
    "            numbers = list(map(int,numbers))\n",
    "            person_test.append(numbers[0])\n",
    "            horiSet_test.append(img.T)\n",
    "            dataSet_test.append(img)\n",
    "            count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting data in desired format and mapping the lables\n",
    "dataSet = np.array(dataSet)\n",
    "train = pd.DataFrame(dataSet)\n",
    "\n",
    "person = np.array(person)\n",
    "train['id'] = person.transpose()\n",
    "#print(train['id'])\n",
    "\n",
    "unique_person = train['id']\n",
    "unique_person = np.array(unique_person)\n",
    "unique_person = np.unique(unique_person)\n",
    "key = range(len(unique_person))\n",
    "\n",
    "roll_dict = dict( zip(unique_person, key))\n",
    "key_roll = np.fromiter(roll_dict.keys(),dtype=int)\n",
    "\n",
    "mapped_roll = np.vectorize(roll_dict.get)(person)\n",
    "train['id'] = mapped_roll.transpose()\n",
    "#print(mapped_roll)\n",
    "\n",
    "y = train['id'].values.astype('int64')\n",
    "images = train.drop(['id'], axis=1, inplace=False)\n",
    "x = (images.values).astype('uint8')\n",
    "\n",
    "X_train = x\n",
    "Y_train = y\n",
    "\n",
    "dataSet_test = np.array(dataSet_test)\n",
    "test = pd.DataFrame(dataSet_test)\n",
    "#print(unique_person+ \" \" +key)\n",
    "\n",
    "person_test = np.array(person_test)\n",
    "test['id'] = person_test.transpose()\n",
    "\n",
    "mapped_roll_test = np.vectorize(roll_dict.get)(person_test)\n",
    "test['id'] = mapped_roll_test.transpose()\n",
    "#print(test['id'])\n",
    "\n",
    "temp = np_utils.to_categorical(test['id'])\n",
    "#print(temp[2])\n",
    "#print(temp.shape)\n",
    "\n",
    "\n",
    "y_test = test['id'].values.astype('int64')\n",
    "images = test.drop(['id'], axis=1, inplace=False)\n",
    "x_test = (images.values).astype('uint8')\n",
    "\n",
    "X_test = x_test\n",
    "Y_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 244 samples, validate on 62 samples\n",
      "Epoch 1/150\n",
      " - 3s - loss: 10.6001 - acc: 0.0246 - val_loss: 12.9810 - val_acc: 0.0000e+00\n",
      "Epoch 2/150\n",
      " - 0s - loss: 12.5369 - acc: 0.0410 - val_loss: 12.6831 - val_acc: 0.0000e+00\n",
      "Epoch 3/150\n",
      " - 0s - loss: 9.9569 - acc: 0.1230 - val_loss: 12.5959 - val_acc: 0.0000e+00\n",
      "Epoch 4/150\n",
      " - 0s - loss: 7.8536 - acc: 0.2295 - val_loss: 11.9320 - val_acc: 0.0000e+00\n",
      "Epoch 5/150\n",
      " - 0s - loss: 5.5419 - acc: 0.3770 - val_loss: 10.9930 - val_acc: 0.0161\n",
      "Epoch 6/150\n",
      " - 0s - loss: 3.6325 - acc: 0.4713 - val_loss: 9.8577 - val_acc: 0.0000e+00\n",
      "Epoch 7/150\n",
      " - 0s - loss: 2.6140 - acc: 0.5082 - val_loss: 9.8630 - val_acc: 0.0323\n",
      "Epoch 8/150\n",
      " - 0s - loss: 1.8283 - acc: 0.6066 - val_loss: 9.9847 - val_acc: 0.0323\n",
      "Epoch 9/150\n",
      " - 0s - loss: 1.3623 - acc: 0.7131 - val_loss: 9.5969 - val_acc: 0.0323\n",
      "Epoch 10/150\n",
      " - 1s - loss: 1.0553 - acc: 0.7213 - val_loss: 9.8939 - val_acc: 0.0323\n",
      "Epoch 11/150\n",
      " - 0s - loss: 0.8059 - acc: 0.8074 - val_loss: 10.4456 - val_acc: 0.0323\n",
      "Epoch 12/150\n",
      " - 0s - loss: 0.6766 - acc: 0.8484 - val_loss: 10.7686 - val_acc: 0.0323\n",
      "Epoch 13/150\n",
      " - 0s - loss: 0.4493 - acc: 0.8566 - val_loss: 11.0883 - val_acc: 0.0323\n",
      "Epoch 14/150\n",
      " - 0s - loss: 0.5320 - acc: 0.8607 - val_loss: 10.7681 - val_acc: 0.0323\n",
      "Epoch 15/150\n",
      " - 0s - loss: 0.3098 - acc: 0.9262 - val_loss: 10.5226 - val_acc: 0.0323\n",
      "Epoch 16/150\n",
      " - 0s - loss: 0.2817 - acc: 0.9221 - val_loss: 10.5092 - val_acc: 0.0323\n",
      "Epoch 17/150\n",
      " - 0s - loss: 0.2168 - acc: 0.9385 - val_loss: 10.9643 - val_acc: 0.0323\n",
      "Epoch 18/150\n",
      " - 0s - loss: 0.1625 - acc: 0.9549 - val_loss: 11.6329 - val_acc: 0.0323\n",
      "Epoch 19/150\n",
      " - 0s - loss: 0.2248 - acc: 0.9467 - val_loss: 12.0545 - val_acc: 0.0323\n",
      "Epoch 20/150\n",
      " - 0s - loss: 0.1534 - acc: 0.9508 - val_loss: 12.1837 - val_acc: 0.0323\n",
      "Epoch 21/150\n",
      " - 0s - loss: 0.1136 - acc: 0.9877 - val_loss: 12.2437 - val_acc: 0.0323\n",
      "Epoch 22/150\n",
      " - 0s - loss: 0.0868 - acc: 0.9672 - val_loss: 12.2701 - val_acc: 0.0323\n",
      "Epoch 23/150\n",
      " - 0s - loss: 0.1261 - acc: 0.9508 - val_loss: 12.3194 - val_acc: 0.0323\n",
      "Epoch 24/150\n",
      " - 0s - loss: 0.1263 - acc: 0.9631 - val_loss: 12.4759 - val_acc: 0.0323\n",
      "Epoch 25/150\n",
      " - 0s - loss: 0.2178 - acc: 0.9508 - val_loss: 12.3451 - val_acc: 0.0323\n",
      "Epoch 26/150\n",
      " - 0s - loss: 0.0685 - acc: 0.9754 - val_loss: 12.3866 - val_acc: 0.0323\n",
      "Epoch 27/150\n",
      " - 0s - loss: 0.0518 - acc: 0.9918 - val_loss: 12.5950 - val_acc: 0.0323\n",
      "Epoch 28/150\n",
      " - 0s - loss: 0.0773 - acc: 0.9713 - val_loss: 12.7060 - val_acc: 0.0323\n",
      "Epoch 29/150\n",
      " - 0s - loss: 0.0940 - acc: 0.9672 - val_loss: 12.7154 - val_acc: 0.0323\n",
      "Epoch 30/150\n",
      " - 0s - loss: 0.1631 - acc: 0.9508 - val_loss: 12.7195 - val_acc: 0.0323\n",
      "Epoch 31/150\n",
      " - 0s - loss: 0.1414 - acc: 0.9508 - val_loss: 12.7256 - val_acc: 0.0323\n",
      "Epoch 32/150\n",
      " - 0s - loss: 0.1059 - acc: 0.9836 - val_loss: 12.8146 - val_acc: 0.0323\n",
      "Epoch 33/150\n",
      " - 0s - loss: 0.1162 - acc: 0.9631 - val_loss: 12.8552 - val_acc: 0.0323\n",
      "Epoch 34/150\n",
      " - 0s - loss: 0.1738 - acc: 0.9508 - val_loss: 12.8990 - val_acc: 0.0323\n",
      "Epoch 35/150\n",
      " - 0s - loss: 0.0758 - acc: 0.9795 - val_loss: 12.9724 - val_acc: 0.0323\n",
      "Epoch 36/150\n",
      " - 0s - loss: 0.0756 - acc: 0.9877 - val_loss: 13.2233 - val_acc: 0.0323\n",
      "Epoch 37/150\n",
      " - 0s - loss: 0.1495 - acc: 0.9590 - val_loss: 13.3184 - val_acc: 0.0323\n",
      "Epoch 38/150\n",
      " - 0s - loss: 0.1087 - acc: 0.9754 - val_loss: 12.5473 - val_acc: 0.0323\n",
      "Epoch 39/150\n",
      " - 0s - loss: 0.0322 - acc: 0.9918 - val_loss: 12.3867 - val_acc: 0.0323\n",
      "Epoch 40/150\n",
      " - 0s - loss: 0.0536 - acc: 0.9836 - val_loss: 12.4688 - val_acc: 0.0323\n",
      "Epoch 41/150\n",
      " - 0s - loss: 0.1174 - acc: 0.9795 - val_loss: 12.4518 - val_acc: 0.0323\n",
      "Epoch 42/150\n",
      " - 0s - loss: 0.0707 - acc: 0.9754 - val_loss: 12.5301 - val_acc: 0.0323\n",
      "Epoch 43/150\n",
      " - 0s - loss: 0.0961 - acc: 0.9631 - val_loss: 12.7993 - val_acc: 0.0323\n",
      "Epoch 44/150\n",
      " - 0s - loss: 0.0429 - acc: 0.9795 - val_loss: 12.8713 - val_acc: 0.0323\n",
      "Epoch 45/150\n",
      " - 0s - loss: 0.1622 - acc: 0.9754 - val_loss: 12.5860 - val_acc: 0.0323\n",
      "Epoch 46/150\n",
      " - 0s - loss: 0.1834 - acc: 0.9672 - val_loss: 12.5357 - val_acc: 0.0323\n",
      "Epoch 47/150\n",
      " - 0s - loss: 0.0599 - acc: 0.9836 - val_loss: 12.5191 - val_acc: 0.0323\n",
      "Epoch 48/150\n",
      " - 0s - loss: 0.0846 - acc: 0.9713 - val_loss: 12.5495 - val_acc: 0.0323\n",
      "Epoch 49/150\n",
      " - 0s - loss: 0.1188 - acc: 0.9713 - val_loss: 12.8009 - val_acc: 0.0323\n",
      "Epoch 50/150\n",
      " - 0s - loss: 0.0531 - acc: 0.9836 - val_loss: 13.0612 - val_acc: 0.0323\n",
      "Epoch 51/150\n",
      " - 1s - loss: 0.0503 - acc: 0.9836 - val_loss: 12.9827 - val_acc: 0.0323\n",
      "Epoch 52/150\n",
      " - 1s - loss: 0.0634 - acc: 0.9754 - val_loss: 13.0379 - val_acc: 0.0323\n",
      "Epoch 53/150\n",
      " - 1s - loss: 0.0451 - acc: 0.9959 - val_loss: 13.0114 - val_acc: 0.0323\n",
      "Epoch 54/150\n",
      " - 0s - loss: 0.0955 - acc: 0.9836 - val_loss: 12.7844 - val_acc: 0.0323\n",
      "Epoch 55/150\n",
      " - 0s - loss: 0.0194 - acc: 0.9918 - val_loss: 12.8009 - val_acc: 0.0323\n",
      "Epoch 56/150\n",
      " - 0s - loss: 0.1487 - acc: 0.9754 - val_loss: 12.6959 - val_acc: 0.0323\n",
      "Epoch 57/150\n",
      " - 0s - loss: 0.1152 - acc: 0.9672 - val_loss: 12.7800 - val_acc: 0.0323\n",
      "Epoch 58/150\n",
      " - 0s - loss: 0.0462 - acc: 0.9877 - val_loss: 12.8843 - val_acc: 0.0323\n",
      "Epoch 59/150\n",
      " - 0s - loss: 0.0471 - acc: 0.9795 - val_loss: 13.0062 - val_acc: 0.0323\n",
      "Epoch 60/150\n",
      " - 0s - loss: 0.0580 - acc: 0.9836 - val_loss: 12.9441 - val_acc: 0.0323\n",
      "Epoch 61/150\n",
      " - 0s - loss: 0.0171 - acc: 0.9918 - val_loss: 12.9788 - val_acc: 0.0323\n",
      "Epoch 62/150\n",
      " - 0s - loss: 0.0970 - acc: 0.9795 - val_loss: 12.9268 - val_acc: 0.0323\n",
      "Epoch 63/150\n",
      " - 0s - loss: 0.0315 - acc: 0.9918 - val_loss: 13.0819 - val_acc: 0.0323\n",
      "Epoch 64/150\n",
      " - 0s - loss: 0.0993 - acc: 0.9877 - val_loss: 13.4064 - val_acc: 0.0323\n",
      "Epoch 65/150\n",
      " - 0s - loss: 0.1210 - acc: 0.9672 - val_loss: 13.6025 - val_acc: 0.0323\n",
      "Epoch 66/150\n",
      " - 0s - loss: 0.1108 - acc: 0.9795 - val_loss: 13.9803 - val_acc: 0.0323\n",
      "Epoch 67/150\n",
      " - 0s - loss: 0.1872 - acc: 0.9795 - val_loss: 13.8831 - val_acc: 0.0323\n",
      "Epoch 68/150\n",
      " - 0s - loss: 0.1456 - acc: 0.9672 - val_loss: 14.1257 - val_acc: 0.0323\n",
      "Epoch 69/150\n",
      " - 0s - loss: 0.0912 - acc: 0.9836 - val_loss: 14.3018 - val_acc: 0.0323\n",
      "Epoch 70/150\n",
      " - 0s - loss: 0.0377 - acc: 0.9877 - val_loss: 14.3423 - val_acc: 0.0323\n",
      "Epoch 71/150\n",
      " - 0s - loss: 0.0810 - acc: 0.9836 - val_loss: 14.3531 - val_acc: 0.0323\n",
      "Epoch 72/150\n",
      " - 0s - loss: 0.0729 - acc: 0.9836 - val_loss: 14.3593 - val_acc: 0.0323\n",
      "Epoch 73/150\n",
      " - 0s - loss: 0.0625 - acc: 0.9754 - val_loss: 14.3158 - val_acc: 0.0323\n",
      "Epoch 74/150\n",
      " - 0s - loss: 0.0663 - acc: 0.9795 - val_loss: 14.3223 - val_acc: 0.0323\n",
      "Epoch 75/150\n",
      " - 0s - loss: 0.0577 - acc: 0.9877 - val_loss: 14.3788 - val_acc: 0.0323\n",
      "Epoch 76/150\n",
      " - 0s - loss: 0.0790 - acc: 0.9795 - val_loss: 14.2619 - val_acc: 0.0323\n",
      "Epoch 77/150\n",
      " - 0s - loss: 0.0914 - acc: 0.9795 - val_loss: 14.1598 - val_acc: 0.0323\n",
      "Epoch 78/150\n",
      " - 0s - loss: 0.1241 - acc: 0.9754 - val_loss: 13.7673 - val_acc: 0.0323\n",
      "Epoch 79/150\n",
      " - 0s - loss: 0.0317 - acc: 0.9918 - val_loss: 13.4665 - val_acc: 0.0323\n",
      "Epoch 80/150\n",
      " - 0s - loss: 0.0310 - acc: 0.9877 - val_loss: 13.2769 - val_acc: 0.0323\n",
      "Epoch 81/150\n",
      " - 0s - loss: 0.0249 - acc: 0.9959 - val_loss: 13.2550 - val_acc: 0.0323\n",
      "Epoch 82/150\n",
      " - 0s - loss: 0.1180 - acc: 0.9754 - val_loss: 13.2552 - val_acc: 0.0323\n",
      "Epoch 83/150\n",
      " - 0s - loss: 0.0273 - acc: 0.9877 - val_loss: 13.1733 - val_acc: 0.0323\n",
      "Epoch 84/150\n",
      " - 0s - loss: 0.1443 - acc: 0.9754 - val_loss: 13.1235 - val_acc: 0.0323\n",
      "Epoch 85/150\n",
      " - 0s - loss: 0.0332 - acc: 0.9959 - val_loss: 13.1031 - val_acc: 0.0323\n",
      "Epoch 86/150\n",
      " - 0s - loss: 0.1476 - acc: 0.9754 - val_loss: 13.0582 - val_acc: 0.0323\n",
      "Epoch 87/150\n",
      " - 0s - loss: 0.0137 - acc: 0.9959 - val_loss: 13.2157 - val_acc: 0.0323\n",
      "Epoch 88/150\n",
      " - 0s - loss: 0.0018 - acc: 1.0000 - val_loss: 13.4656 - val_acc: 0.0323\n",
      "Epoch 89/150\n",
      " - 0s - loss: 0.1075 - acc: 0.9795 - val_loss: 13.3772 - val_acc: 0.0323\n",
      "Epoch 90/150\n",
      " - 0s - loss: 0.0396 - acc: 0.9795 - val_loss: 13.2483 - val_acc: 0.0323\n",
      "Epoch 91/150\n",
      " - 0s - loss: 0.0176 - acc: 0.9877 - val_loss: 13.2323 - val_acc: 0.0323\n",
      "Epoch 92/150\n",
      " - 0s - loss: 0.0022 - acc: 1.0000 - val_loss: 13.3582 - val_acc: 0.0323\n",
      "Epoch 93/150\n",
      " - 0s - loss: 0.0695 - acc: 0.9836 - val_loss: 13.4433 - val_acc: 0.0323\n",
      "Epoch 94/150\n",
      " - 0s - loss: 0.0271 - acc: 0.9918 - val_loss: 13.5473 - val_acc: 0.0323\n",
      "Epoch 95/150\n",
      " - 0s - loss: 0.0163 - acc: 0.9959 - val_loss: 13.5068 - val_acc: 0.0323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/150\n",
      " - 0s - loss: 0.0332 - acc: 0.9836 - val_loss: 13.4411 - val_acc: 0.0323\n",
      "Epoch 97/150\n",
      " - 0s - loss: 0.0296 - acc: 0.9877 - val_loss: 13.3489 - val_acc: 0.0323\n",
      "Epoch 98/150\n",
      " - 1s - loss: 0.1350 - acc: 0.9631 - val_loss: 13.3290 - val_acc: 0.0323\n",
      "Epoch 99/150\n",
      " - 1s - loss: 0.0747 - acc: 0.9795 - val_loss: 13.4774 - val_acc: 0.0323\n",
      "Epoch 100/150\n",
      " - 1s - loss: 0.0270 - acc: 0.9877 - val_loss: 13.8358 - val_acc: 0.0323\n",
      "Epoch 101/150\n",
      " - 1s - loss: 0.1154 - acc: 0.9672 - val_loss: 13.8664 - val_acc: 0.0323\n",
      "Epoch 102/150\n",
      " - 1s - loss: 0.0576 - acc: 0.9836 - val_loss: 13.8916 - val_acc: 0.0323\n",
      "Epoch 103/150\n",
      " - 1s - loss: 0.0475 - acc: 0.9836 - val_loss: 14.1765 - val_acc: 0.0323\n",
      "Epoch 104/150\n",
      " - 1s - loss: 0.0721 - acc: 0.9877 - val_loss: 14.3950 - val_acc: 0.0323\n",
      "Epoch 105/150\n",
      " - 1s - loss: 0.0545 - acc: 0.9918 - val_loss: 14.5368 - val_acc: 0.0323\n",
      "Epoch 106/150\n",
      " - 1s - loss: 0.0246 - acc: 0.9959 - val_loss: 14.6380 - val_acc: 0.0323\n",
      "Epoch 107/150\n",
      " - 0s - loss: 0.1401 - acc: 0.9631 - val_loss: 14.3697 - val_acc: 0.0323\n",
      "Epoch 108/150\n",
      " - 1s - loss: 0.0284 - acc: 0.9959 - val_loss: 14.2816 - val_acc: 0.0323\n",
      "Epoch 109/150\n",
      " - 1s - loss: 0.0910 - acc: 0.9795 - val_loss: 14.2727 - val_acc: 0.0323\n",
      "Epoch 110/150\n",
      " - 1s - loss: 0.0688 - acc: 0.9877 - val_loss: 14.3572 - val_acc: 0.0323\n",
      "Epoch 111/150\n",
      " - 1s - loss: 0.0250 - acc: 0.9877 - val_loss: 14.4322 - val_acc: 0.0323\n",
      "Epoch 112/150\n",
      " - 1s - loss: 0.2203 - acc: 0.9754 - val_loss: 14.4809 - val_acc: 0.0323\n",
      "Epoch 113/150\n",
      " - 1s - loss: 0.0143 - acc: 0.9959 - val_loss: 14.3986 - val_acc: 0.0323\n",
      "Epoch 114/150\n",
      " - 1s - loss: 0.0286 - acc: 0.9877 - val_loss: 14.3530 - val_acc: 0.0323\n",
      "Epoch 115/150\n",
      " - 1s - loss: 0.0287 - acc: 0.9918 - val_loss: 14.3416 - val_acc: 0.0323\n",
      "Epoch 116/150\n",
      " - 1s - loss: 0.0808 - acc: 0.9713 - val_loss: 14.4315 - val_acc: 0.0323\n",
      "Epoch 117/150\n",
      " - 1s - loss: 0.0275 - acc: 0.9918 - val_loss: 14.5081 - val_acc: 0.0323\n",
      "Epoch 118/150\n",
      " - 1s - loss: 0.0243 - acc: 0.9918 - val_loss: 14.6995 - val_acc: 0.0323\n",
      "Epoch 119/150\n",
      " - 1s - loss: 0.1612 - acc: 0.9795 - val_loss: 14.4852 - val_acc: 0.0323\n",
      "Epoch 120/150\n",
      " - 1s - loss: 0.1712 - acc: 0.9754 - val_loss: 14.2549 - val_acc: 0.0323\n",
      "Epoch 121/150\n",
      " - 1s - loss: 0.1969 - acc: 0.9672 - val_loss: 13.5954 - val_acc: 0.0323\n",
      "Epoch 122/150\n",
      " - 0s - loss: 0.0531 - acc: 0.9877 - val_loss: 13.2378 - val_acc: 0.0323\n",
      "Epoch 123/150\n",
      " - 1s - loss: 0.0231 - acc: 0.9918 - val_loss: 13.3169 - val_acc: 0.0323\n",
      "Epoch 124/150\n",
      " - 1s - loss: 0.0179 - acc: 0.9959 - val_loss: 13.4267 - val_acc: 0.0323\n",
      "Epoch 125/150\n",
      " - 1s - loss: 0.0762 - acc: 0.9795 - val_loss: 13.4936 - val_acc: 0.0323\n",
      "Epoch 126/150\n",
      " - 1s - loss: 0.0666 - acc: 0.9877 - val_loss: 13.5568 - val_acc: 0.0323\n",
      "Epoch 127/150\n",
      " - 1s - loss: 0.0144 - acc: 0.9959 - val_loss: 13.5365 - val_acc: 0.0323\n",
      "Epoch 128/150\n",
      " - 1s - loss: 0.0188 - acc: 0.9959 - val_loss: 13.5713 - val_acc: 0.0323\n",
      "Epoch 129/150\n",
      " - 1s - loss: 0.0872 - acc: 0.9836 - val_loss: 13.6218 - val_acc: 0.0323\n",
      "Epoch 130/150\n",
      " - 1s - loss: 0.0227 - acc: 0.9959 - val_loss: 13.8269 - val_acc: 0.0323\n",
      "Epoch 131/150\n",
      " - 1s - loss: 0.0725 - acc: 0.9836 - val_loss: 14.0282 - val_acc: 0.0323\n",
      "Epoch 132/150\n",
      " - 0s - loss: 0.0680 - acc: 0.9877 - val_loss: 14.1895 - val_acc: 0.0323\n",
      "Epoch 133/150\n",
      " - 1s - loss: 0.0384 - acc: 0.9836 - val_loss: 14.3731 - val_acc: 0.0323\n",
      "Epoch 134/150\n",
      " - 1s - loss: 0.1137 - acc: 0.9795 - val_loss: 14.4244 - val_acc: 0.0323\n",
      "Epoch 135/150\n",
      " - 1s - loss: 0.0090 - acc: 0.9959 - val_loss: 14.5514 - val_acc: 0.0323\n",
      "Epoch 136/150\n",
      " - 0s - loss: 0.1380 - acc: 0.9877 - val_loss: 14.4751 - val_acc: 0.0323\n",
      "Epoch 137/150\n",
      " - 1s - loss: 0.0645 - acc: 0.9877 - val_loss: 14.1259 - val_acc: 0.0323\n",
      "Epoch 138/150\n",
      " - 0s - loss: 0.0487 - acc: 0.9918 - val_loss: 14.2094 - val_acc: 0.0323\n",
      "Epoch 139/150\n",
      " - 1s - loss: 0.0317 - acc: 0.9959 - val_loss: 14.2501 - val_acc: 0.0323\n",
      "Epoch 140/150\n",
      " - 0s - loss: 0.0975 - acc: 0.9836 - val_loss: 14.1694 - val_acc: 0.0323\n",
      "Epoch 141/150\n",
      " - 1s - loss: 0.0937 - acc: 0.9836 - val_loss: 14.2036 - val_acc: 0.0323\n",
      "Epoch 142/150\n",
      " - 1s - loss: 0.0261 - acc: 0.9918 - val_loss: 14.2641 - val_acc: 0.0323\n",
      "Epoch 143/150\n",
      " - 1s - loss: 0.0357 - acc: 0.9877 - val_loss: 14.3405 - val_acc: 0.0323\n",
      "Epoch 144/150\n",
      " - 1s - loss: 0.0981 - acc: 0.9795 - val_loss: 14.4393 - val_acc: 0.0161\n",
      "Epoch 145/150\n",
      " - 1s - loss: 0.1468 - acc: 0.9672 - val_loss: 14.4958 - val_acc: 0.0323\n",
      "Epoch 146/150\n",
      " - 0s - loss: 0.0446 - acc: 0.9836 - val_loss: 14.6438 - val_acc: 0.0323\n",
      "Epoch 147/150\n",
      " - 1s - loss: 0.0452 - acc: 0.9877 - val_loss: 14.8818 - val_acc: 0.0323\n",
      "Epoch 148/150\n",
      " - 0s - loss: 0.0331 - acc: 0.9836 - val_loss: 14.9811 - val_acc: 0.0323\n",
      "Epoch 149/150\n",
      " - 1s - loss: 0.1009 - acc: 0.9877 - val_loss: 14.8898 - val_acc: 0.0323\n",
      "Epoch 150/150\n",
      " - 1s - loss: 0.2043 - acc: 0.9549 - val_loss: 14.6347 - val_acc: 0.0323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f9b6212a20>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Defining and training of the neural network\n",
    "model = models.Sequential()\n",
    "layers = 2\n",
    "units = 256\n",
    "\n",
    "#Input layer\n",
    "model.add(Dense(units, input_dim=40000, activation='relu'))\n",
    "\n",
    "#Hidden Layer\n",
    "for i in range(layers):\n",
    "    model.add(Dense(124, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "#Output layer\n",
    "model.add(Dense(62, activation='softmax'))\n",
    "\n",
    "#Building model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Training model\n",
    "model.fit(X_train,Y_train,batch_size=125,validation_split=0.2,epochs=150,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test, verbose=0)\n",
    "\n",
    "def write_predictions(predictions, fname):\n",
    "    pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)), \"id\": predictions}).to_csv(fname, index=False, header=True)\n",
    "\n",
    "write_predictions(key_roll[predictions], \"out.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.6209677419354839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 9,  0,  1,  1,  2,  3,  3,  3,  4,  4,  5,  5,  6,  6,  7,  7, 41,\n",
       "       41,  9, 24, 10, 10, 11, 11, 12, 12, 13, 13,  3, 14,  5, 15, 34,  4,\n",
       "       17, 17, 18, 18, 19, 19, 20, 20, 21, 21, 22, 22, 23, 23, 24, 24, 25,\n",
       "       25,  1, 26, 27, 27, 28, 28, 29, 29, 30, 30, 31, 31, 32, 32,  1,  1,\n",
       "       34, 34, 35, 42, 36, 36, 18, 19, 38, 38, 39, 39, 16,  8, 41, 41, 42,\n",
       "       26, 43, 43, 44, 44, 24, 15, 46, 15,  3, 20, 48, 48, 49, 49, 42, 23,\n",
       "        8,  8, 38, 38, 21,  4,  5, 16,  3,  3, 38, 34, 34, 34, 33,  3, 23,\n",
       "       42,  4, 23, 48, 39], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.read_csv('out.csv')\n",
    "result = result['id']\n",
    "result = np.array(result)\n",
    "error = np.array(Y_test - result)\n",
    "error = error[error != 0]\n",
    "error = error.size/Y_test.size\n",
    "\n",
    "print('Accuracy : ',1-error)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision score, micro-averaged over all classes: 0.64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "for i in range(35):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(temp[:, i],\n",
    "                                                        score[:, i])\n",
    "    average_precision[i] = average_precision_score(temp[:, i], score[:, i])\n",
    "\n",
    "# A \"micro-average\": quantifying score on all classes jointly\n",
    "precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(temp.ravel(),\n",
    "    score.ravel())\n",
    "average_precision[\"micro\"] = average_precision_score(temp, score,\n",
    "                                                     average=\"micro\")\n",
    "print('Average precision score, micro-averaged over all classes: {0:0.2f}'\n",
    "      .format(average_precision[\"micro\"]))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.step(recall['micro'], precision['micro'], color='b', alpha=0.9,\n",
    "         where='post')\n",
    "#plt.fill_between(recall[\"micro\"], precision[\"micro\"], step='post', alpha=0.2,\n",
    "#                 color='b')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title(\n",
    "    'Average precision score, micro-averaged over all classes: AP={0:0.2f}'\n",
    "    .format(average_precision[\"micro\"]))\n",
    "plt.show()\n",
    "fig.savefig('HOG-ANN(sketch translation image).png',dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
